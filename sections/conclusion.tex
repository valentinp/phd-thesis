\chapter{Conclusion}
\epigraph{What we call the beginning is often the end. And to make an end is to make a beginning.}{\textsc{T.S. Eliot}}
\begin{figure}
\begin{subfigure}[]{0.24\textwidth}
    \includegraphics[width=\textwidth]{conclusion/probe}
  \caption{PROBE \\ (\Cref{ch:probe}).}
\end{subfigure}
\begin{subfigure}[]{0.24\textwidth}
    \includegraphics[width=\textwidth]{conclusion/sun_bcnn}
  \caption{Sun-BCNN \\ (\Cref{ch:sun-bcnn}).}
\end{subfigure}
\begin{subfigure}[]{0.24\textwidth}
    \includegraphics[width=\textwidth]{conclusion/dpc}
  \caption{DPC-Net \\ (\Cref{ch:dpc}).}
\end{subfigure}
\begin{subfigure}[]{0.22\textwidth}
    \includegraphics[width=\textwidth]{conclusion/hydranet}
  \caption{HydraNet \\ (\Cref{ch:hydranet}).}
\end{subfigure}
\caption{Four approaches presented in this dissertation.}
\end{figure}

This dissertation has presented several ways to improve the performance of visual egomotion pipelines through data-driven probabilistic models that extract latent information in existing sensor data.  We presented four examples of such learned models, grouping them into those quantify uncertainty, those that correct bias, and those that augment the pipeline by predicting complementary information. We close with a final summary of novel contributions associated with each chapter, a discussion of potential future work, and some concluding remarks.

\section{Summary of Contributions}

\subsection{Predictive Robust Estimation}

We began with an approach that constructed a heteroscedastic noise model to facilitate what we called predictively robust estimation or PROBE. With PROBE, we contributed
\begin{enumerate}
\item a probabilistic model for indirect stereo visual odometry, leading to a predictive robust algorithm for inference on that model,
\item two different approaches to constructing the robust algorithm: one baseds on k-nearest neighbours (Appendix \ref{app:appendix_probe_knn}), and one based on Generalized Kernel (GK) estimation (\Cref{ch:probe}),
\item a procedure for training our model using pairs of stereo images with known relative transforms, and
\item an iterative, expectation-maximization approach to train our GK model when the relative ground truth egomotion was unavailable.
\end{enumerate}

%\noindent A total of three publications associated with PROBE,
%\begin{itemize}
%	\item \bibentry{2016_Peretroukhin_PROBE-GK}
%	\item \bibentry{2015_Peretroukhin_PROBE}
%	\item \bibentry{2015_Peretroukhin_Get}.
%\end{itemize}


\subsection{Sun-BCNN}


With Sun-BCNN, we applied modern deep learning to the problem of illumination direction in outdoor environments. In sum, the novel contributions were:
\begin{enumerate}
\item the application of a Bayesian CNN to the problem of sun direction estimation, incorporating the resulting covariance estimates into a visual odometry pipeline; 
\item an empirical demonstration that a Bayesian CNN with dropout layers after each convolutional and fully-connected layer can achieve state-of-the-art accuracy at test time;
\item a loss function that incorporated a 3D unit-length sun direction vector, appropriate for full 6-DOF pose estimation;
\item experimental results on over 30~km of visual navigation data in urban \citep{Geiger2013-ky} and planetary analogue \citep{Furgale2012-kk} environments; 
\item an investigation into the sensitivity of the Bayesian CNN-based sun estimate to cloud cover, camera and environment changes, and measurement parameterization; and
\item open-source software.
\end{enumerate}

%\noindent Sun-BCNN and its origin in learned sun sensors have three associated publications,
%\begin{itemize}
%	\item \bibentry{2018_Peretroukhin_Inferring}
%	\item \bibentry{2017_Peretroukhin_Reducing}
%	\item \bibentry{2017_Clement_Improving}.
%\end{itemize}


\subsection{Deep Pose Corrections}

Next, we generalized the results of Sun-BCNN to learn full six degree-of-freedom corrections for a particular egomotion pipeline and a given environment with DPC-Net. Our contributions included

\begin{enumerate}
	\item the formulation of a novel deep corrective approach to egomotion estimation,
	\item a novel cost function for deep $\LieGroupSE{3}$ regression that naturally balances translation and rotation errors, and
	\item an open-source implementation of DPC-Net in \texttt{PyTorch}.
\end{enumerate}

%\noindent DPC-Net was published in a journal publication,
%\begin{itemize}
%	\item \bibentry{2018_Peretroukhin_Deep}.
%\end{itemize}


\subsection{Deep Probabilistic Inference of $\LieGroupSO{3}$ with HydraNet}


Finally, we applied the lessons of DPC-Net and Sun-BCNN to focus on learning rotation estimates through a network structure that incorporated both aleatoric and epistemic uncertainty. We fused these rotation estimates with the motion estimates of a classical pipeline through pose graph optimization. With this work, we contributed
\begin{enumerate}
\item a deep network structure we called \textit{HydraNet} that builds on prior work to produce meaningful uncertainties (including both aleatoric and epistemic components) over unconstrained targets,
\item a loss formulation and mathematical framework that extends HydraNet to means and covariances of the rotation group $\LieGroupSO{3}$,
\item and open source code for $\LieGroupSO{3}$ regression with uncertainty.
\end{enumerate}

%\noindent HydraNet was published in a refereed workshop paper,
%\begin{itemize}
%\item \bibentry{2019_Peretroukhin_Deep}.
%\end{itemize}
\section{Future Work}

\begin{figure}[h!]
\begin{center}
		\includegraphics[width=0.9\textwidth]{conclusion/learning_fusion.pdf}
		\caption{Three ways to combine learning with classical pipelines. This dissertation presented four examples that fall into the first two categories: correction and augmentation. We believe there is ample opportunity to explore the third category, initialization, in future work.}
  	\label{fig:conc_learning_fusion}
\end{center}
\end{figure}


There are many avenues for future work. The fusion of classical methods with learned models has the potential to improve many types of estimators within mobile robotics and computer vision. In this dissertation, we focused on improving a canonical visual odometry pipeline based on Gauss-Newton optimization. For more general tasks like SLAM, Gauss-Newton-based optimization methods can often produce sub-optimal results due to local minima in highly-non-convex loss surfaces; indeed, their use is often predicated on having access to accurate initializations of state variables. To address this deficiency, a number of recent publications (e.g., \cite{Rosen2019-kk}) have applied methods from the field of convex optimization to SLAM and pose-graph optimization. Their efforts have produced global solvers with certifiably-optimal solutions. 

We see two potential ways learning can further this thread of research: (1) by using learned models as parametric inputs into certifiable global solvers to better model uncertainty and data association, and (2) by applying learning to the problem of initialization in highly non-convex optimization problems.

The first approach would leverage deep networks to parameterize some part of a loss function that would then be optimized through global convex-optimization-based solvers (e.g., similar to \cite{amos2017optnet}). In this way, the final localization and mapping results would be ‘optimal’, in the sense that they are the global minima of a given loss function, and ‘robust’, in the sense that they adapt the loss function parameters for a given environment.

The second approach would apply learning to the problem of initializing state variables in the basin of convergence of their global optima.  In this dissertation, we used learning to either correct or augment a classical pipeline, yet it may often be beneficial to use these learned models as priors built on semantic information. Such a prior would act as an initialization which would then be refined by classical optimization techniques (\Cref{fig:conc_learning_fusion}). The motivation for this approach is two-fold. First, if high metric accuracy is not desired, learned methods can encode large-scale regions in a similar way to classical image retrieval techniques---in fact, recent work \citep{sattler_understanding_2019} on absolute pose regression with CNNs suggests that techniques like PoseNet are more akin to image retrieval techniques than metric re-localization---while better leveraging, or being robust to, place-specific landmarks, seasonal appearance changes, and sensor deficiencies. Second, by applying a \textit{certifiable} global solver to the refinement step, the method can be robust to poor initializations by simply rejecting certain solutions and querying the model for another initial guess. This would obviate the need to certify the learning method directly, and only require that the model eventually produce some reasonable initialization which can be refined to a certifiably globally-optimal state.
  
\begin{remark}{Dissertation as Dialectic}
The dialectic method of the Georg Hegel involves a triad: a thesis, antithesis and synthesis.
This dissertation has been an attempt at a cogent synthesis of the thesis posed by the classical visual egomotion pipeline with the antithesis posed by data-driven end-to-end learning techniques.
My hope is that the synthesizing methods proposed herein will prove to be useful within the field of visual state estimation, and for the broader robotics community. 
\end{remark}
\newpage
\section{Coda: In Search of Elegance}
\epigraph{The phenomena of the world which have to be explained present countless ends to us, of which one only can be the right one; they resemble an intricate tangle of thread, with many false end-threads hanging from it. He who finds out the right one can disentangle the whole.}{\textsc{Arthur Schopenhauer}, \textit{Parerga and Paralipomena}}

%A fascination on machines to a fascination with people
%Data-driven learning is in many ways humans waving the white flag to the overwhelming complexity of the world
%We relinquish the dream of simplification and interpretation 
%And instead we are satisfied with only prediction
%Hubris of 'hand design'
%Puppeteers and roboticists
%In search of elegance

Looking back on my academic journey, I see a path from a fascination with the possible applications of autonomous systems to a fascination with autonomy \textit{in-and-of-itself}. As a budding researcher, I saw robust, accurate perception as a means towards an end. An end which entailed truly autonomous systems `perceiving' and `interpreting' their surroundings with the goal of exploring distant planets and navigating busy urban streets. Now, however, I see `perception' as an end in itself with a plethora of fascinating mathematical, philosophical and ethical challenges that can be tackled in light of, but not subservient to, the potential goals of some grander autonomous system. Throughout this transition, I have become more interested not only in the flesh and blood of perception systems, but also in the \textit{spirit} of them. If perception is one of the bridges we must build to reach the land of autonomy, I am concerned not only with the structural integrity that lets us cross it today, but also with an elegance and rigour that lets it serve as a model for posterity. 

With this in mind, I want to address a concerning shift that has occurred in the research community throughout my academic career. Many researchers who work on algorithms that enable autonomy (not only in perception, but also in planning and controls) have given up on the dream of modelling the world with the tools of Euclid, Newton and Euler in favour of methods that rely on exemplary data to `train' arbitrarily complex predictive black-box models. In my estimation, this shift has brought with it a certain sense of resignation to the overwhelming complexity of the world. We are often content to use vague notions of complexity as reason to avoid building analytic models. Instead, we turn to crude, inscrutable surrogates of our own brains to model what we do not want to. This, I believe, is a tempting mistake. Although these solutions may serve as useful tools to temporarily bridge gaps in our understanding of the world, we will inevitably deplete the low-hanging empirical fruits that they can bear, and we will be left with a deep sense of dissatisfaction that only elegance can fill. 

I am certainly not the first or the last person who has taken issue with data-driven methods. Noam Chomsky gives the following critique of purely statistical approaches to science\footnote{\url{http://norvig.com/chomsky.html}}. Consider the study of bee colonies. In order to to extract interpretable models of their behaviour (e.g., there is a queen bee, there are worker bees, etc.), one has to observe these colonies meticulously over generations. So why not avoid that entire endeavour and use a data-driven approach? We could set up a camera to observe a bee colony and collect data over several years. By tracking each bee, we could use the tools of modern machine learning to construct and train a large parametric model of each of their positions. Once complete, we could then query this model with a new image from our camera and recover, with extreme precision, the predicted location of each bee. This may allow us to improve honey production, but what have we learned? Is this an elegant model of bee behaviour? Have we not just transformed the problem of understanding the bees into one of understanding this surrogate model? Now consider doing the same with celestial objects--Kepler be damned!

Some may argue that the entire goal of science is predicting the future states of nature, so elegance is irrelevant. I vehemently disagree. I would rather have an interpretable model that is wrong during specific situations (where I can verify that certain assumptions are violated), rather than an obfuscated model which has vague limits to its predictive power.

If history is any judge, the models that stand the test of time are ones that are born out of our meticulous labour and enlightened insight to extract salient principles out of the complexity of the world. The hope that this labour can be replaced with black-box surrogates that indirectly learn these same principles is troubling and, in my view, unnecessary. No matter how much anthropomorphic language we use to describe these surrogates (endowing them with `understanding', `attention', and `forgetfulness'), they will always be limited by our own ability to collect sufficient data, and by our ability to craft them in such a way as to consume significant amounts of training exemplars without `overfitting' to them. What's more, if these models have any interaction with the world, they will also affect the world, and we are committing ourselves to an endless game of cat-and-mouse. Although it may seem that our time is best spent crafting ever-more-clever surrogates, we will soon reach a point where we would be better off using the time and resources towards studying a particular problem more directly.

I do not want to cast aspersions flippantly.  The transition to data-driven approaches in computer vision happened for good reason and with much hesitation. The elegance of analytic models has historically only been exceeded by their inability to model the often inelegant `real world'. At the turn of the twenty-first century, roboticists were joking that the dirty secret of much of computer vision is that it doesn't work. Recent efforts into combining the connectionist ideas of the 20th century with the computational power accessible in the 21st have undoubtedly created systems that do attain impressive empirical results, and there is a constant stream of new theoretical insights into the types of structures	 and optimization methods that work well in a given domain.

However, as the world becomes more connected and complex with every passing day, I think it is of utmost importance that autonomy researchers are not tempted to focus solely on empirical results at the cost of elegant solutions. It is now well-accepted that data-driven methods are not the panacea (like it might have seemed for a brief moment a few years ago) to all problems in autonomy. However, this passive agreement may not be enough. Instead, we need to actively suppress the urge to try and solve a problem first through general `learning' methods that are becoming more and more easy to implement and less and less easy to understand.  We do not need to relinquish the dream of understanding the world and relegate ourselves to simply predicting it by any means possible. We can instead strive to simplify it and interpret it. If after significant effort we fail at that goal, and only then, should we turn to data-driven learned models to fill in the gaps in our understanding.

