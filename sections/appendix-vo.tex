\chapter{Visual Odometry Implementation Details}
\label{chap:appendix_vo}

This appendix presents some implementation details (including all Jacobians) for a standard VO pipeline. You can find a \texttt{python} implementation of this in \texttt{pyslam}. The math is largely based on \cite{Barfoot2017-ri}.

\section{Overview}
\begin{enumerate}
\item Set the initial camera pose, $\Transform_{cw}$, to a known transform $\Transform_{c_0w}$ that defines a world coordinate frame of the first camera frame, $\CoordinateFrame{c_0}$, with respect to world frame $\CoordinateFrame{w}$.
\item Match a set of $N_t$ landmarks that have been tracked between two stereo camera poses, $\CoordinateFrame{c_0}$ and a subsequent frame $\CoordinateFrame{c_1}$, and have the image coordinates $\{\ImageLandmark{i}{c_0}, \ImageLandmark{i}{c_1}\}_{i=1}^{N_t}$. This step is non-trivial in general, but for our work, we largely rely on the framework $\texttt{viso2}$ to provide these putative correspondences.
\item Perform RANSAC using the method of \cite{Umeyama1991-ws} and described in \cite{Barfoot2017-ri} to reject outlying tracks.
\item Select initial guess of the relative transform, $\Transform_{c_1c_0} =  \Transform_t$. Solve the M-estimation problem:  
\begin{equation}
\label{eq:vo_app_robust_loss}
  \Transform_{c_1c_0}^* = \Transform_t^* = \ArgMin{\Transform\in\text{SE}(3)}\sum_{i=1}^{N} 
  \rho\left(\sqrt{\Transpose{\Vector{e}_{i}} \GeneralCovariance_{i}^{-1} \Vector{e}_{i}}\right) = \ArgMin{\Transform\in\text{SE}(3)}\sum_{i=1}^{N} 
  \rho(\epsilon_i),
\end{equation}
where $\rho(\cdot)$ can be selected based on empirical performance, $\Vector{e}_i$ is the reprojection error, $\Vector{e}_{i}(\Transform_t)  = \ImageLandmark{i}{c_1} - \ProjectionFunction( \Transform_t 
    \ProjectionFunction^{-1}( \ImageLandmark{i}{c_0} ) )$, and $\ProjectionFunction$ is the stereo camera model.
\item Update the current camera pose as:
\begin{equation}
	\Transform_{cw} \leftarrow  \Transform_t \Transform_{cw}
\end{equation}
\end{enumerate}

\section{Solution with Robust Loss}

In order to solve \Cref{eq:vo_app_robust_loss}, we use IRLS, and solve the problem,

\begin{equation}
\Transform^* = \ArgMin{\Transform\in\text{SE}(3)}\frac{1}{2} \sum_{i=1}^{N} 
\Transpose{\Vector{e}_{i}} \Matrix{M}_{i} \Vector{e}_{i} 
\end{equation}

where $ \Matrix{M}_i(\Transform) \definedtobe \frac{1}{\epsilon_i} \PartialDerivative{\rho}{\epsilon_i}  \GeneralCovariance_{i}^{-1}$.
To solve this, we begin at an operating point, we linearize about an operating point $\Transform_t^{(n)}$, as:
\begin{equation}
 \delta \Vector{\xi}^* = \ArgMin{\delta \Vector{\xi} \in \RealNumbers{}^6} \mathcal{L}(\delta \Vector{\xi}) = \frac{1}{2}\sum_{i=1}^{N_t} 
  \Transpose{\left(\Vector{e}_{i}
  - \Matrix J_{i} \delta\Vector{\xi}\right)}
\Matrix{M}_i
 \left(\Vector{e}_{i}
 - \Matrix J_{i} \delta\Vector{\xi}\right)
  \end{equation}
where $\Vector{e}_{i} = \Vector{e}_{i}(\Transform_t^{(n)})$, $\Vector{J}_{i} = \Vector{J}_{i}(\Transform_t^{(n)})$ and $\Matrix{M}_{i} = \Matrix{M}_{i}(\Transform_t^{(n)})$. This is solved by the normal equations,
\begin{align}
\delta\Vector{\xi}^* &= \left( \sum_{i=1}^{N_t} \Matrix{J}_{i}^T \Matrix{M}_i \Matrix{J}_{i} \right)^{-1} \left( \sum_{i=1}^{N_t} \Matrix{J}_{i}^T\Matrix{M}_i \Vector{e}_i \right).
\end{align}
Given an optimal we update the operating point using:
\begin{equation}
	  \Transform_t^{(n+1)} = \MatExp{\delta\Vector{\xi}^*} \Transform_t^{(n)} 
\end{equation}

\section{Deriving the Necessary Jacobians}

We can compute $\Matrix{J}_{i}$ by beginning with $\Vector{e}_{i}(\Transform_t)  = \ImageLandmark{i}{c_1} - \ProjectionFunction( \Transform_t 
    \ProjectionFunction^{-1}( \ImageLandmark{i}{c_0} ) )$ and making the following first order approximations:
    \begin{align}
    	\Transform_t &\approx (\IdentityMatrix + \delta\Vector{\xi}^{\wedge}) \Transform_t^{(n)} \\
    	\ProjectionFunction(\boldsymbol{p}) & \approx \ProjectionFunction(\boldsymbol{p}^{(n)}) + \Matrix{J}_p (\boldsymbol{p}^{(n)})  \delta \boldsymbol{p}.
    \end{align}
    
where $\Matrix{J}_p(\boldsymbol{p}^{(n)}) = \at{\PartialDerivative{\Vector{f}}{\boldsymbol{p}}}{\boldsymbol{p}^{(n)}}$ and $\boldsymbol{p}^{(n)} = \Transform_t^{(n)} 
    \ProjectionFunction^{-1}(\ImageLandmark{i}{c_0})$. Next we note that,

\begin{align}
	\boldsymbol{p}^{(n)} + \delta \boldsymbol{p} &\approx (\IdentityMatrix + \delta\Vector{\xi}^{\wedge}) \Transform_t^{(n)} 
    \ProjectionFunction^{-1}( \ImageLandmark{i}{c_0} ) \\
    &= \underbrace{\Transform_t^{(n)} 
    \ProjectionFunction^{-1}(\ImageLandmark{i}{c_0})}_{\boldsymbol{p}^{(n)}} + \delta\Vector{\xi}^{\wedge}\underbrace{\Transform_t^{(n)} 
    \ProjectionFunction^{-1}(\ImageLandmark{i}{c_0})}_{\boldsymbol{p}^{(n)}} \\
    &= \boldsymbol{p}^{(n)} + \delta\Vector{\xi}^{\wedge} \boldsymbol{p}^{(n)} \\
    &= \boldsymbol{p}^{(n)} + (\boldsymbol{p}^{(n)})^\odot \delta\Vector{\xi}
\end{align}


which allows us to write $\delta \boldsymbol{p} = (\boldsymbol{p}^{(n)})^\odot \delta\Vector{\xi}$. Here we have used the notation from \cite{Barfoot2017-ri}, to define:
\begin{equation}
\boldsymbol{p}^\odot = \bbm \Vector{p} \\ 1 \ebm^\odot = \bbm \IdentityMatrix & -\Vector{p}^\wedge \\ \Vector{0}^T & \Vector{0}^T\ebm.
\end{equation}
Combining everything, we have:
\begin{align}
	\Vector{e}_i (\delta \Vector{\xi})  &\approx \underbrace{\ImageLandmark{i}{c_1} - \ProjectionFunction(\boldsymbol{p}^{(n)})}_{\Vector{e}_i(\Transform_t^{(n)})} -  \Matrix{J}_p \delta \boldsymbol{p}\\
	&=  \Vector{e}_i(\Transform_t^{(n)}) - \Matrix{J}_p(\boldsymbol{p}^{(n)}) (\boldsymbol{p}^{(n)})^\odot \delta\Vector{\xi} \\ 
	&=  \Vector{e}_i(\Transform_t^{(n)}) - \underbrace{\Matrix{J}_p( \Transform_t^{(n)} 
    \ProjectionFunction^{-1}(\ImageLandmark{i}{c_0})) ( \Transform_t^{(n)} 
    \ProjectionFunction^{-1}(\ImageLandmark{i}{c_0}))^\odot}_{\Matrix{J}_i} \delta\Vector{\xi} 
\end{align}
which concludes our derivation. For a stereo camera model defined with the origin in the left camera frame,
 \begin{equation}
	\ImageLandmark{i}{c} = \bbm u_l \\ v_l \\ d  \ebm  
  =\ProjectionFunction(\HomogeneousPoint{i}{c}) =  \ProjectionFunction(\bbm x \\ y \\ z \\ 1 \ebm) = 
  = \Matrix{M} \frac{1}{z} \HomogeneousPoint{i}{c},
\end{equation}
where
\begin{equation}
\Matrix{M} = \bbm f & 0 & c_u & 0 \\ 0 & f & c_v & 0 \\ 0 & 0 & 0 & fb \ebm,
\end{equation}
the Jacobian, $\Matrix{J}_p$ is given by
\begin{equation}
\Matrix{J}_p = \PartialDerivative{\Vector{f}}{\boldsymbol{p}} = \bbm \frac{f}{z} & 0 & -f \frac{x}{z^2} & 0 \\ 0 & \frac{f}{z} & -f \frac{y}{z^2} & 0 \\ 0 & 0 & -f \frac{b}{z^2} & 0 \ebm.
\end{equation}




 