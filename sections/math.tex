\chapter{Preliminaries}
\section{Stereo Visual Odometry}

In our frame-to-frame sparse stereo odometry pipeline,  the objective is to find
$\Transform_t\in\text{SE}(3)$, the rigid transform between two subsequent stereo camera poses (note that the temporal index $t$ refers to the set of two stereo camera poses). We begin by rectifying, then stereo and temporally
matching the set of 4 images to generate the corresponding locations of a set
of $N_t$ visual landmarks in each stereo pair.  Each landmark corresponds to a
point in space, expressed in homogeneous coordinates in the camera frame as
$\HomogeneousPoint{i}{t} := \Transpose{\bbm p_1 & p_2 & p_3 & p_4 \ebm} \in
\HomogeneousNumbers[3]$.  The stereo-camera model, $\ProjectionFunction$,
projects a landmark expressed in homogeneous coordinates into image space, so
that $\ImageLandmark{i}{t}$, the stereo pixel coordinates of landmark $i$ in the first camera pose at time $t$, is given
by 
\begin{equation}
	\ImageLandmark{i}{t} = \bbm u_l \\ v_l \\ u_r \\ v_r \ebm 
  = \ProjectionFunction(\HomogeneousPoint{i}{t}) 
  = \Matrix{M} \frac{1}{p_3}\HomogeneousPoint{i}{t},
\end{equation}
where
\begin{equation}
 \Matrix{M} = \bbm f_u & 0 & c_u & f_u \frac{b}{2} \\ 0 & f_v & c_v & 0 \\ f_u 
                        & 0 & c_u & -f_u\frac{b}{2} \\ 0 & f_b & c_v & 0 \ebm.
\end{equation}
Here, $\{c_u, c_v\}$, $\{f_u, f_v\}$, and $b$ are the principal points, focal
lengths and baseline of the stereo camera respectively. Note that in this
formulation, the stereo camera frame is centered between the two individual
lenses.  

We triangulate landmarks in the first camera frame, $\ImageLandmark{i}{t}$, and re-project
them into the second frame, $\ImageLandmark{i}{t}'$. We model errors due to sensor noise
and quantization as a Gaussian distribution in image space with a known covariance
$\Covariance$,
\begin{equation}
  p(\ImageLandmark{i}{t}' \vert \ImageLandmark{i}{t}, \Transform_t,
  \Covariance)
  =\NormalDistribution\left(\Vector{e}_{i,t}(\Transform_t); \Vector 0, \Covariance\right), 
\end{equation}
where
\begin{equation}
 \Vector{e}_{i,t} = \ImageLandmark{i}{t}' - \ProjectionFunction( \Transform_t 
    \ProjectionFunction^{-1}( \ImageLandmark{i}{t} ) ).	
   \label{eq:image_error}
\end{equation}
  The maximum likelihood transform,
$\Transform_t^*$, is then given by 
\begin{equation}
  \Transform_t^* = \ArgMin{\Transform_t\in\text{SE}(3)}\sum_{i=1}^{N_t} 
  \Transpose{\Vector{e}_{i,t}} \Covariance^{-1} \Vector{e}_{i,t}.
\end{equation}
This is a nonlinear least squares problem, and can be solved iteratively using
standard techniques. During iteration $n$, we represent the transform as the
product of an estimate $\Transform^{(n)}\in\text{SE}(3)$ and a perturbation
$\delta\Vector{\xi}\in\RealNumbers[6]$ represented in exponential
coordinates:
\begin{equation}
  \Transform_t = \exp{\left( \delta\Vector{\xi}^{\wedge}
  \right)} \Transform_t^{(n)}.
\end{equation}
The wedge operator $(\cdot)^\wedge$ is defined (following
\citet{barfoot2014associating}) as both the map
$\RealNumbers[3]\to\mathfrak{so}(3)$,  
\begin{equation}
\Vector \phi ^\wedge \triangleq \bbm \phi_1 \\ \phi_2 \\ \phi_3 \ebm^\wedge	= \bbm 0 &
-\phi_3 & \phi_2 \\ \phi_3 & 0 & -\phi_1 \\ -\phi_2 & \phi_1 & 0 \ebm,
\label{eq:wedgeOpRotation}
\end{equation}
and the map $\RealNumbers[6]\to\mathfrak{se}(3)$,
\begin{equation}
  \Vector \xi^\wedge \triangleq \bbm \Vector \rho \\ \Vector \phi \ebm ^\wedge = \bbm
  \Vector \phi^\wedge & \Vector \rho \\ \Transpose{\Vector{0}} &  0 \ebm.	
\end{equation}
Linearizing the transform for small perturbations $\delta\Vector{\xi}$
yields a linear least-squares problem:
\begin{equation}
  \mathcal{L}(\delta \Vector{\xi}) = \frac{1}{2}\sum_{i=1}^{N_t} 
  \Transpose{\left(\Vector{e}_{i,t}^{(n)}
  - \Matrix J_{i,t}^{(n)} \delta\Vector{\xi}\right)}
\Covariance^{-1}
 \left(\Vector{e}_{i,t}^{(n)}
 - \Matrix J_{i,t}^{(n)} \delta\Vector{\xi}\right)
  \end{equation}
Here, $\Matrix J_{i,t}^{(n)}$ is the Jacobian matrix of the reprojection error.
The explicit form of the Jacobian matrix is omitted for brevity but can be
found in our supplemental materials.\footnote{\url{http://groups.csail.mit.edu/rrg/peretroukhin_icra16/supplemental.pdf}}

Rearranging, we see the minimizing perturbation is the solution to a
linear system of equations:
\begin{equation}
  \delta\Vector{\xi}^{(n)} = 
  \left( \sum_{i=1}^{N_t} \Transpose{\Matrix J}_{i,t}
  \ImageLandmarkCovariance{}{}^{-1} \Matrix J_{i,t} \right)^{-1}
  \sum_{i=1}^{N_t} \Transpose{\Matrix J}_{i,t}
  \Covariance^{-1} \Vector{e}_{i,t}^{(n)}. 
\label{eq:least-squares-iteration}
\end{equation}
We then update the estimated transform and proceed to the next iteration.
\begin{equation}
  \Transform_t^{(n+1)} = \exp{\left( \delta\Vector{\xi}^{(n)\wedge}
  \right)} \Transform_t^{(n)}. \label{eq:update}
\end{equation}
There are many reasonable choices for both the initial transform
$\Transform_t^{(0)}$ and for the conditions under which we terminate
iteration. We initialize the estimated transform to identity, and iteratively
perform the update given by \cref{eq:update} until we see a relative change in
the squared error of less than one percent after an update. 

\section{Robust Estimation}
\subsection{The effects of outliers}
\subsection{M-estimation}

\section{Matrix Lie Groups}
\subsection{Manifolds}
\subsection{Local vs. Global Perturbations}


 